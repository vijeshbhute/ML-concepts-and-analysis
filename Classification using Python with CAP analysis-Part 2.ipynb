{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1531481",
   "metadata": {},
   "source": [
    "# Comparison of Classification methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4160f1",
   "metadata": {},
   "source": [
    "Author: Dr. Vijesh J. Bhute   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2fd0d2",
   "metadata": {},
   "source": [
    "Highlights of this notebook:\n",
    "<ul><li>Performs classification of a dataset with more than 2 features.</li>\n",
    "    <li> Compares different methods using Accuracy and Cumulative Accuracy Profile analysis. </li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d94672",
   "metadata": {},
   "source": [
    "<b>Types of classification models:</b>\n",
    "<ul><li>Logistical regression</li>\n",
    "    <li>K-Nearest Neighbours</li>\n",
    "    <li>Support vector machine (SVM)</li>\n",
    "    <li>Kernel SVM</li>\n",
    "    <li>Naive Bayes</li>\n",
    "    <li>Decision Tree</li>\n",
    "    <li>Random Forest</li>\n",
    "    </ul> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4591b4d4",
   "metadata": {},
   "source": [
    "## Accuracy and Confusion matrix for classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f72811",
   "metadata": {},
   "source": [
    "For classification problems, accuracy for the model is given by, $$\\text{Accuracy} =\\frac{\\text{TN+TP}}{\\text{TN+FN+TP+FP}}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717f95a",
   "metadata": {},
   "source": [
    "You can also look at the confusion matrix to see a summary of how the model has performed:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <th>Predicted No ($0$)</th>\n",
    "    <th>Predicted Yes ($1$)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Actual No ($0$)</th>\n",
    "    <td>TN</td>\n",
    "    <td>FP</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Actual Yes ($1$)</th>\n",
    "    <td>FN</td>\n",
    "    <td>TP</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7558a4c",
   "metadata": {},
   "source": [
    "### CAP analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398878ca",
   "metadata": {},
   "source": [
    "CAP: Cumulative Accuracy Profile is often used to compare models as accuracy alone may not be an ideal metric. \n",
    "<br><br>\n",
    "This requires evaluating accuracy ratio. \n",
    "<br><br>\n",
    "The first method to analyse the CAP Curve is using Area Under Curve. Letâ€™s consider area under random model as $a$. We calculate the Accuracy Rate using the following steps:\n",
    "<ul><li>Calculate the area under the perfect model ($a_P$) till the random model $a$</li>\n",
    "    <li>Calculate the area under the prediction model ($a_R$) till the random model ($a$)</li>\n",
    "    <li>Calculate Accuracy Ratio (AR) $= a_R / a_P$</li></ul>\n",
    "The closer the Accuracy Ratio is to the 1, better is the model.\n",
    "<br> CAP analysis is adapted from <a href=\"https://www.kaggle.com/code/rohandawar/cap-cumulative-accuracy-profile-analysis-1/notebook\" target=\"_blank\">Kaggle website</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2e8e7",
   "metadata": {
    "colab_type": "text",
    "id": "LWd1UlMnhT2s"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944a3883",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvGPUQaHhXfL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf351f",
   "metadata": {
    "colab_type": "text",
    "id": "K1VMqkGvhc3-"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2703b6",
   "metadata": {},
   "source": [
    "I am going to use a breast cancer dataset from UCI for comparing different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f565b11",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M52QDmyzhh9s",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0             1000025                5                        1   \n",
       "1             1002945                5                        4   \n",
       "2             1015425                3                        1   \n",
       "3             1016277                6                        8   \n",
       "4             1017023                4                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "\n",
       "   Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0            1                3                1        1      2  \n",
       "1           10                3                2        1      2  \n",
       "2            2                3                1        1      2  \n",
       "3            4                3                7        1      2  \n",
       "4            1                3                1        1      2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/Data_UCI_Breast cancer_classification.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdea2d3",
   "metadata": {},
   "source": [
    "<ul><li>Last column is a binary variable. This is already encoded as 2 (benign) or 4 (malignant) and it might be beneficial to make this 0 and 1 by further encoding using Label Encoder.</li>\n",
    "    <li>First column is not relevant for modelling and should be excluded from the training and test set</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d065653",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54903a22",
   "metadata": {},
   "source": [
    "### Optional: converting Class or target categorical variable as 0 and 1 instead of 2 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e2fcd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y= le.fit_transform (y)\n",
    "#There is also ordinal encoder when variable is not only categorical but also has certain order (high, low for example)\n",
    "sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7694f639",
   "metadata": {
    "colab_type": "text",
    "id": "YvxIPVyMhmKp"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e344bd8c",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVzJWAXIhxoC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56878df1",
   "metadata": {},
   "source": [
    "<b>Note:</b> The predictors/features are of similar orders of magnitude. If they were different, then it would have been important to perform feature scaling (especially since the following models will relate to classification based on these features and there isn't any explicit relationship between $y$ and $x$). \n",
    "<br>\n",
    "In this case, it is also fine to do the feature scaling as it will ensure that all features have similar average and standard deviation<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e98934",
   "metadata": {
    "colab_type": "text",
    "id": "kW3c7UYih0hT"
   },
   "source": [
    "### Feature Scaling (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78235836",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fQlDPKCh8sc"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test) #Fit using training set and transform the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c000c89",
   "metadata": {
    "colab_type": "text",
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229b561",
   "metadata": {},
   "source": [
    "Multiple linear regression model is given by, $$ y = b_0 + b_1 *x_1 + b_2 *x_2$$\n",
    "<br>In logistic regression, you fit a function which lies in $0-1$. For example, sigmoid function, which is given by, $$p = \\frac{1}{1+e^{-y}}$$\n",
    "<br> Where $p$ is the probability which takes the values between $0$ and $1$. Solving above equation for $y$, we get, $$y = \\ln \\Big(\\frac{p}{1-p}\\Big) = b_0 + b_1*x_1 + b_2*x_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "212bac5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2125,
     "status": "ok",
     "timestamp": 1588265315505,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "e0pFVAmciHQs",
    "outputId": "67f64468-abdb-4fe7-cce9-de0037119610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126   4]\n",
      " [  5  70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logModel = LogisticRegression(random_state = 0)\n",
    "logModel.fit(X_train, y_train)\n",
    "y_predict_logModel= logModel.predict(X_test) #Predicting test set\n",
    "#print(logModel.predict(sc.transform([[30,87000]]))) #Predicting a new result using the model\n",
    "from sklearn.metrics import confusion_matrix #Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict_logModel)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a01a6",
   "metadata": {},
   "source": [
    "## K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddc87678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126   4]\n",
      " [  6  69]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbhute\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kNN = KNeighborsClassifier(n_neighbors=5, metric = 'minkowski',p=2) #minkowski with p=2 corresponds to Euclidean distance\n",
    "kNN.fit(X_train, y_train)\n",
    "y_predict_kNN=kNN.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict_kNN)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e03fba",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78144b3f",
   "metadata": {},
   "source": [
    "### Linear kernel for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83a386fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126   4]\n",
      " [  4  71]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "LinearSVMmodel = SVC(kernel='linear', random_state = 0)\n",
    "LinearSVMmodel.fit(X_train, y_train)\n",
    "y_predict_LinSVM=LinearSVMmodel.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_predict_LinSVM)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ae059",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc5bdda",
   "metadata": {},
   "source": [
    "Types of common kernel functions:<br>\n",
    "<ul><li>Gaussian Radial basis function (RBF)</li>\n",
    "    <li>Sigmoid kernel </li>\n",
    "    <li>Polynomial kernel</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaf28ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[123   7]\n",
      " [  3  72]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "kSVMmodel = SVC() #default kernel is rbf (radial basis function)\n",
    "#Other kernels include 'linear', â€˜polyâ€™, â€˜rbfâ€™, â€˜sigmoidâ€™, â€˜precomputedâ€™ or callable, default=â€™rbfâ€™\n",
    "kSVMmodel.fit(X_train, y_train)\n",
    "y_predict_kSVM=kSVMmodel.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_predict_kSVM)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919d571",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51745335",
   "metadata": {},
   "source": [
    "<ul><li>Naive Bayes makes several assumptions but can be used even if the dataset don't satisfy these assumptions. </li><li>The most important assumption is that the <b>features are linearly independent of each other</b>. This is not true in most cases.</li> <li>\n",
    "In spite of their apparently over-simplified assumptions, naive Bayes classifiers have worked quite well in many real-world situations, famously document classification and spam filtering. They require a small amount of training data to estimate the necessary parameters. </li>\n",
    "    <li><b>This algorithm is good for classification but very good for estimation!</b></li>\n",
    "<li>There are different types of Naive Bayes classifiers which differ mainly by the assumptions they make regarding the distribution of $P(x_i | y)$. These are:\n",
    "<ul><li> Gaussian Naive Bayes</li>\n",
    "    <li> Multinomial Naive Bayes </li>\n",
    "    <li> Complement Naive Bayes</li>\n",
    "    <li> Bernoulli Naive Bayes</li>\n",
    "    <li> Categorical Naive Bayes </li></ul></li></ul>\n",
    "You can learn more about Naive Bayes classifier from <a href=\"https://scikit-learn.org/stable/modules/naive_bayes.html\" target=\"_blank\">scikit learn website</a> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc1cc81",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bc50543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[121   9]\n",
      " [  2  73]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB #MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "NBmodel = GaussianNB()\n",
    "NBmodel.fit(X_train,y_train)\n",
    "y_predict_NB= NBmodel.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_predict_NB)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86252482",
   "metadata": {},
   "source": [
    "### Decision Trees classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f53355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[125   5]\n",
      " [  6  69]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecTreeModel= DecisionTreeClassifier()\n",
    "DecTreeModel.fit(X_train,y_train)\n",
    "y_predict_DecTree= DecTreeModel.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_predict_DecTree)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366cd111",
   "metadata": {},
   "source": [
    "## Random Forests classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08f8db5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126   4]\n",
      " [  6  69]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFModel = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
    "RFModel.fit(X_train, y_train)\n",
    "y_predict_RF= RFModel.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_predict_RF)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e382e",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20814d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbhute\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\vbhute\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:211: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>Training set</th>\n",
       "      <th>Test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.970711</td>\n",
       "      <td>0.946341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Trees</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.979079</td>\n",
       "      <td>0.951220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kernel SVM</td>\n",
       "      <td>0.981172</td>\n",
       "      <td>0.951220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Log Regression</td>\n",
       "      <td>0.976987</td>\n",
       "      <td>0.956098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.976987</td>\n",
       "      <td>0.960976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model name  Training set  Test set\n",
       "4     Naive Bayes      0.970711  0.946341\n",
       "5  Decision Trees      1.000000  0.946341\n",
       "1             kNN      0.979079  0.951220\n",
       "3      Kernel SVM      0.981172  0.951220\n",
       "6  Random Forests      1.000000  0.951220\n",
       "0  Log Regression      0.976987  0.956098\n",
       "2      Linear SVM      0.976987  0.960976"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = {'Model name':['Log Regression', 'kNN', \n",
    "                     'Linear SVM', 'Kernel SVM', \n",
    "                     'Naive Bayes', 'Decision Trees', \n",
    "                     'Random Forests'], \n",
    "       'Training set':[logModel.score(X_train, y_train), kNN.score(X_train, y_train), \n",
    "                       LinearSVMmodel.score(X_train,y_train), kSVMmodel.score(X_train,y_train), \n",
    "                      NBmodel.score(X_train,y_train), DecTreeModel.score(X_train, y_train),\n",
    "                      RFModel.score(X_train,y_train)], \n",
    "       'Test set':[logModel.score(X_test, y_test), kNN.score(X_test,y_test), \n",
    "                   LinearSVMmodel.score(X_test,y_test), kSVMmodel.score(X_test,y_test), \n",
    "                  NBmodel.score(X_test,y_test), DecTreeModel.score(X_test, y_test),\n",
    "                  RFModel.score(X_test,y_test)]}\n",
    "accuracyDF = pd.DataFrame(data = dat)\n",
    "#accuracy[0]= logModel.score(X_train, y_train)\n",
    "#accuracyTest\n",
    "accuracyDF.sort_values('Test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88be9400",
   "metadata": {},
   "source": [
    "For this dataset, with default parameters, Linear SVM and Log regression perform better than other classifier models based on accuracy. Accuracy may not be the best metric (accuracy paradox can be an issue). Cumulative Accuracy Profile can be compared for different models to get a better metric for comparison of classification models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e069e",
   "metadata": {},
   "source": [
    "### CAP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b35fd885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ab29e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAP_analysis(y_test, y_predict):\n",
    "    total = len(y_test)\n",
    "    one_count = np.sum(y_test)\n",
    "    \n",
    "    lm = [y for _,y in sorted(zip(y_predict,y_test), reverse=True)]\n",
    "    xaxis = np.arange(0, total+1)\n",
    "    yaxis = np.append([0], np.cumsum(lm))\n",
    "    \n",
    "    # Area under Random Model\n",
    "    a = auc([0, total], [0, one_count])\n",
    "\n",
    "    # Area between Perfect and Random Model\n",
    "    aP = auc([0, one_count, total], [0, one_count, one_count]) - a\n",
    "\n",
    "    # Area between Trained and Random Model\n",
    "    aR = auc(xaxis, yaxis) - a\n",
    "\n",
    "    return aR / aP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23fe5e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datCAP = [CAP_analysis(y_test, y_predict_logModel), CAP_analysis(y_test, y_predict_kNN), \n",
    "                       CAP_analysis(y_test, y_predict_LinSVM), CAP_analysis(y_test, y_predict_kSVM), \n",
    "                      CAP_analysis(y_test, y_predict_NB), CAP_analysis(y_test, y_predict_DecTree),\n",
    "                      CAP_analysis(y_test, y_predict_RF)]\n",
    "accuracyDF['Accuracy Ratio (CAP)'] = datCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a8eea2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>Training set</th>\n",
       "      <th>Test set</th>\n",
       "      <th>Accuracy Ratio (CAP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Trees</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946341</td>\n",
       "      <td>0.993846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.979079</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.995077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.995077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kernel SVM</td>\n",
       "      <td>0.981172</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.995692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Log Regression</td>\n",
       "      <td>0.976987</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>0.995897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.970711</td>\n",
       "      <td>0.946341</td>\n",
       "      <td>0.996308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.976987</td>\n",
       "      <td>0.960976</td>\n",
       "      <td>0.996718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model name  Training set  Test set  Accuracy Ratio (CAP)\n",
       "5  Decision Trees      1.000000  0.946341              0.993846\n",
       "1             kNN      0.979079  0.951220              0.995077\n",
       "6  Random Forests      1.000000  0.951220              0.995077\n",
       "3      Kernel SVM      0.981172  0.951220              0.995692\n",
       "0  Log Regression      0.976987  0.956098              0.995897\n",
       "4     Naive Bayes      0.970711  0.946341              0.996308\n",
       "2      Linear SVM      0.976987  0.960976              0.996718"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracyDF.sort_values('Accuracy Ratio (CAP)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b8df8",
   "metadata": {},
   "source": [
    "Linear SVM model performs best based on both accuracy in predicting the test set and based on accuracy ration evaluated using CAP analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
